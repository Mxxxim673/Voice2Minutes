import React, { useState, useCallback } from 'react';
import { useTranslation } from 'react-i18next';
import { useDropzone } from 'react-dropzone';
import { useAuth } from '../../hooks/useAuth';
import RecordingModal from '../../components/RecordingModal/RecordingModal';
import { transcribeAudio } from '../../services/audioService';
import { exportToWord } from '../../utils/exportUtils';
import { getAudioDuration, truncateAudioForLimit } from '../../services/usageService';
import { usageTracker } from '../../services/usageTracker';
import { formatRemainingTime, formatDuration } from '../../utils/timeFormat';
import './AudioToText.css';

interface TranscriptionData {
  text: string;
  audioFile?: File;
}

const AudioToText: React.FC = () => {
  const { t } = useTranslation();
  const { user, isGuest, updateUserQuota, ensureGuestMode } = useAuth();
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcriptionResult, setTranscriptionResult] = useState<TranscriptionData | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [uploadedFile, setUploadedFile] = useState<File | null>(null);
  const [isRecordingModalOpen, setIsRecordingModalOpen] = useState(false);
  const [usageLimitWarning, setUsageLimitWarning] = useState<string | null>(null);
  const [currentUsedMinutes, setCurrentUsedMinutes] = useState(0);
  const [fileDetectedDuration, setFileDetectedDuration] = useState<number | null>(null);
  const [fileUploadError, setFileUploadError] = useState<string | null>(null);

  // æ›´æ–°ä½¿ç”¨é‡æ•°æ®
  const updateUsageData = async () => {
    try {
      const realUsedMinutes = await usageTracker.getCurrentUserTotalUsage();
      setCurrentUsedMinutes(realUsedMinutes);
      console.log('ğŸ”„ AudioToTexté¡µé¢ä½¿ç”¨é‡æ•°æ®å·²æ›´æ–°:', realUsedMinutes.toFixed(2), 'åˆ†é’Ÿ');
    } catch (error) {
      console.error('âŒ æ›´æ–°ä½¿ç”¨é‡æ•°æ®å¤±è´¥:', error);
      // å›é€€åˆ°åŸæœ‰æ•°æ®è·å–æ–¹å¼
      const isGuestUser = isGuest || !user || user?.userType === 'guest';
      const fallbackUsage = isGuestUser ? Number(localStorage.getItem('guestUsedMinutes') || '0') : (user?.usedMinutes || 0);
      setCurrentUsedMinutes(fallbackUsage);
    }
  };

  // Restore transcription result on page load
  React.useEffect(() => {
    const storedTranscription = localStorage.getItem('transcriptionResult');
    if (storedTranscription) {
      setTranscriptionResult({
        text: storedTranscription,
        audioFile: undefined // File can't be serialized, so it's undefined on restore
      });
    }
  }, []);

  // æ›´æ–°ä½¿ç”¨é‡æ•°æ®
  React.useEffect(() => {
    updateUsageData();
  }, [user, isGuest]);

  // Only ensure guest mode if explicitly in guest mode
  React.useEffect(() => {
    if (!user && localStorage.getItem('guestMode') === 'true') {
      console.log('ğŸ“„ AudioToTexté¡µé¢åŠ è½½ï¼Œå·²æœ‰è®¿å®¢æ¨¡å¼æ ‡è¯†ï¼Œæ›´æ–°è®¿å®¢çŠ¶æ€...');
      ensureGuestMode().catch(error => {
        console.error('âŒ è®¿å®¢æ¨¡å¼æ›´æ–°å¤±è´¥:', error);
      });
    }
  }, [user, ensureGuestMode]);

  const onDrop = useCallback(async (acceptedFiles: File[]) => {
    const file = acceptedFiles[0];
    if (file) {
      try {
        console.log('ğŸ“ ä¸Šä¼ æ–‡ä»¶:', file.name, 'å¤§å°:', (file.size / 1024 / 1024).toFixed(2), 'MB');
        
        // æ¸…é™¤ä¹‹å‰çš„çŠ¶æ€
        setError(null);
        setUsageLimitWarning(null);
        setFileUploadError(null);
        setFileDetectedDuration(null);
        
        // æ£€æµ‹éŸ³é¢‘æ—¶é•¿
        try {
          const fileDuration = await getAudioDuration(file);
          setFileDetectedDuration(fileDuration);
          
          // ç»Ÿä¸€çš„é…é¢è®¡ç®—é€»è¾‘
          const isGuestUser = isGuest || !user || user?.userType === 'guest';
          const isAdmin = user?.email === 'max.z.software@gmail.com';
          const totalQuota = isAdmin ? 99999 : (isGuestUser ? 5 : (user?.quotaMinutes || 10));
          const remainingMinutes = Math.max(0, totalQuota - currentUsedMinutes);
          
          console.log('ğŸ“‹ æ–‡ä»¶æ£€æµ‹å®Œæˆ:', {
            æ–‡ä»¶: file.name,
            æ£€æµ‹æ—¶é•¿: formatDuration(fileDuration),
            å‰©ä½™é…é¢: formatRemainingTime(remainingMinutes)
          });
          
          // æ£€æŸ¥æ˜¯å¦è¶…å‡ºå‰©ä½™æ—¶é•¿ï¼ˆç®¡ç†å‘˜è·³è¿‡æ£€æŸ¥ï¼‰
          if (!isAdmin && fileDuration > remainingMinutes) {
            setFileUploadError(
              `æ–‡ä»¶æ—¶é•¿ ${formatDuration(fileDuration)} è¶…å‡ºå‰©ä½™æ—¶é•¿ ${formatRemainingTime(remainingMinutes)}ï¼Œæ— æ³•ä¸Šä¼ æ­¤æ–‡ä»¶ã€‚`
            );
            // ä¸è®¾ç½® uploadedFileï¼Œé˜»æ­¢åç»­å¤„ç†
            return;
          } else {
            // æ—¶é•¿åˆé€‚ï¼Œå¯ä»¥ä¸Šä¼ 
            setUploadedFile(file);
            
            if (!isAdmin && fileDuration > remainingMinutes * 0.8) {
              // å¦‚æœä½¿ç”¨äº†80%ä»¥ä¸Šçš„å‰©ä½™æ—¶é•¿ï¼Œç»™å‡ºæé†’ï¼ˆç®¡ç†å‘˜è·³è¿‡ï¼‰
              setUsageLimitWarning(
                `æ³¨æ„ï¼šæ­¤æ–‡ä»¶å°†æ¶ˆè€— ${formatDuration(fileDuration)}ï¼Œæ¥è¿‘æ‚¨çš„å‰©ä½™æ—¶é•¿é™åˆ¶ã€‚`
              );
            }
          }
        } catch (error) {
          console.error('âŒ æ–‡ä»¶æ—¶é•¿æ£€æµ‹å¤±è´¥:', error);
          setFileUploadError('æ— æ³•æ£€æµ‹éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚');
        }
        
      } catch (error) {
        console.error('File processing error:', error);
        setError('æ–‡ä»¶å¤„ç†é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®');
      }
    }
  }, [isGuest, user, t]);

  const { getRootProps, getInputProps, isDragActive } = useDropzone({
    onDrop,
    accept: {
      'audio/*': ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.mp4', '.mpeg', '.mpga', '.webm']
    },
    multiple: false,
    // No maxSize limit - handle large files with chunking
  });

  const handleTranscription = async (audioFile: File) => {
    setIsProcessing(true);
    setError(null);
    setUsageLimitWarning(null);
    
    try {
      // ç»Ÿä¸€çš„ç”¨æˆ·ç±»å‹å’Œé…é¢æ£€æŸ¥
      const isGuestUser = isGuest || !user || user?.userType === 'guest';
      const isAdmin = user?.email === 'max.z.software@gmail.com';
      const userType = isAdmin ? 'admin' : (isGuestUser ? 'guest' : (user?.userType || 'trial'));
      
      // è·å–å½“å‰ä½¿ç”¨é‡ - ä½¿ç”¨çœŸå®æ•°æ®
      const currentUsage = currentUsedMinutes;
      
      // è·å–éŸ³é¢‘æ—¶é•¿
      let originalDuration: number;
      try {
        originalDuration = await getAudioDuration(audioFile);
      } catch (error) {
        console.error('âŒ éŸ³é¢‘æ—¶é•¿æ£€æµ‹å®Œå…¨å¤±è´¥:', error);
        setError('æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®');
        setIsProcessing(false);
        return;
      }
      
      // è®¡ç®—å‰©ä½™é…é¢
      const totalQuota = isGuestUser ? 5 : (user?.quotaMinutes || 10);
      const remainingMinutes = Math.max(0, totalQuota - currentUsage);
      
      console.log(`ğŸµ éŸ³é¢‘æ—¶é•¿: ${formatDuration(originalDuration)}, å‰©ä½™é…é¢: ${formatRemainingTime(remainingMinutes)}`);
      console.log(`ğŸ‘¤ ç”¨æˆ·ç±»å‹: ${userType}, æ¸¸å®¢ç”¨æˆ·: ${isGuestUser}`);
      
      let actualAudioFile = audioFile;
      let actualDuration = originalDuration;
      let wasTruncated = false;
      
      // æ™ºèƒ½å¤„ç†ï¼šå¦‚æœæ²¡æœ‰å‰©ä½™é…é¢ï¼Œç›´æ¥æç¤ºç”¨æˆ·
      if (remainingMinutes <= 0) {
        setError(isGuestUser ? 
          t('audioToText.guestQuotaExhausted') : 
          t('audioToText.quotaExhaustedGeneral')
        );
        setIsProcessing(false);
        return;
      }
      
      // å¦‚æœéŸ³é¢‘æ—¶é•¿è¶…è¿‡å‰©ä½™é…é¢ï¼Œè¿›è¡Œæˆªæ–­å¤„ç†ï¼ˆä½†ä»…é™éç®¡ç†å‘˜ç”¨æˆ·ï¼‰
      if (!isAdmin && originalDuration > remainingMinutes) {
        console.log(`âš ï¸ éŸ³é¢‘è¶…å‡ºå‰©ä½™é…é¢ï¼Œå°†æˆªæ–­å¤„ç†: ${formatDuration(originalDuration)} -> ${formatRemainingTime(remainingMinutes)}`);
        
        const truncateResult = await truncateAudioForLimit(audioFile, remainingMinutes);
        actualAudioFile = truncateResult.file;
        actualDuration = Math.min(originalDuration, remainingMinutes);
        wasTruncated = true;
        
        setUsageLimitWarning(
          `âš ï¸ éŸ³é¢‘æ™‚é•· ${formatDuration(originalDuration)} ãŒæ®‹ã‚Šåˆ©ç”¨æ  ${formatRemainingTime(remainingMinutes)} ã‚’è¶…éã—ã¦ã„ã‚‹ãŸã‚ã€æœ€åˆã® ${formatDuration(actualDuration)} åˆ†ã®ã¿å¤‰æ›ã—ã¾ã™`
        );
      }
      
      // æ‰§è¡Œè½¬å½•ï¼ˆæ— è®ºæ˜¯å¦æˆªæ–­éƒ½å…è®¸è¿›è¡Œï¼‰
      const transcriptionText = await transcribeAudio(actualAudioFile, userType, currentUsage);
      
      // ä½¿ç”¨æ–°çš„ä½¿ç”¨é‡è¿½è¸ªç³»ç»Ÿè®°å½•çœŸå®ä½¿ç”¨é‡ï¼ˆè½¬æ¢ä¸ºç§’ï¼‰
      const actualDurationSeconds = actualDuration * 60;
      await usageTracker.recordUsage(
        actualDurationSeconds, 
        actualAudioFile.name, 
        actualAudioFile.size, 
        transcriptionText.length
      );
      
      // æ£€æŸ¥é…é¢çŠ¶æ€å¹¶ç»™å‡ºç›¸åº”æç¤º
      const quotaLimit = isGuestUser ? 5 : (user?.quotaMinutes || 10);
      const newUsedMinutes = currentUsage + actualDuration;
      if (newUsedMinutes >= quotaLimit) {
        setUsageLimitWarning(
          isGuestUser ? 
          'ğŸ‰ ã‚²ã‚¹ãƒˆä½“é¨“ãŒå®Œäº†ã—ã¾ã—ãŸï¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™»éŒ²ã§10åˆ†ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«æ™‚é–“ã‚’å–å¾—ã§ãã¾ã™ã€‚' :
          'ğŸ‰ ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸï¼'
        );
      } else if (quotaLimit - newUsedMinutes <= 1) {
        setUsageLimitWarning(`â° æ³¨æ„ï¼šæ®‹ã‚Šåˆ©ç”¨æ  ${formatRemainingTime(quotaLimit - newUsedMinutes)}`);
      }
      
      // æ›´æ–°é¡µé¢æ˜¾ç¤ºçš„ä½¿ç”¨é‡æ•°æ®
      await updateUsageData();
      
      const result: TranscriptionData = {
        text: transcriptionText,
        audioFile: audioFile
      };
      
      setTranscriptionResult(result);
      localStorage.setItem('transcriptionResult', result.text);
      
      console.log(`âœ… è»¢å†™å®Œäº†ã€ä½¿ç”¨æ™‚é–“: ${formatDuration(actualDuration)}${wasTruncated ? ' (æˆªæ–­æ¸ˆã¿)' : ''}`);
      
    } catch (error) {
      console.error('âŒ è½¬å½•å¤±è´¥:', error);
      setError(error instanceof Error ? error.message : 'è½¬å½•è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯');
    } finally {
      setIsProcessing(false);
    }
  };

  const handleStartTranscription = () => {
    if (uploadedFile) {
      handleTranscription(uploadedFile);
    }
  };

  // éŸ³é¢‘æ ¼å¼è½¬æ¢å‡½æ•°
  const convertAudioToSupportedFormat = async (audioBlob: Blob): Promise<File> => {
    const originalMimeType = audioBlob.type || 'audio/webm';
    console.log('ğŸµ åŸå§‹éŸ³é¢‘æ ¼å¼:', originalMimeType);
    
    // OpenAI API æ”¯æŒçš„æ ¼å¼åˆ—è¡¨ï¼ˆåŒ…æ‹¬å„ç§å˜ä½“ï¼‰
    const supportedFormats = [
      'audio/flac', 'audio/m4a', 'audio/x-m4a', 'audio/mp3', 'audio/mp4', 
      'audio/mpeg', 'audio/mpga', 'audio/oga', 'audio/ogg', 
      'audio/wav', 'audio/webm'
    ];
    
    // æ£€æŸ¥å½“å‰æ ¼å¼æ˜¯å¦è¢«æ”¯æŒ
    const isDirectlySupported = supportedFormats.some(format => 
      originalMimeType.startsWith(format)
    );
    
    if (isDirectlySupported) {
      // æ ¼å¼å·²æ”¯æŒï¼Œç›´æ¥ä½¿ç”¨
      const fileExtension = getFileExtension(originalMimeType);
      const cleanMimeType = getCleanMimeType(originalMimeType);
      console.log('âœ… æ ¼å¼å·²æ”¯æŒï¼Œç›´æ¥ä½¿ç”¨:', cleanMimeType);
      return new File([audioBlob], `recording.${fileExtension}`, { type: cleanMimeType });
    }
    
    // ä¸æ”¯æŒçš„æ ¼å¼ï¼Œè½¬æ¢ä¸ºWAVï¼ˆæœ€å…¼å®¹çš„æ ¼å¼ï¼‰
    console.log('ğŸ”„ æ ¼å¼ä¸æ”¯æŒï¼Œè½¬æ¢ä¸º WAV...');
    try {
      const wavFile = await convertToWav(audioBlob);
      console.log('âœ… æˆåŠŸè½¬æ¢ä¸º WAV æ ¼å¼ï¼Œå¤§å°:', wavFile.size, 'bytes');
      return wavFile;
    } catch (error) {
      console.error('âŒ æ ¼å¼è½¬æ¢å¤±è´¥:', error);
      // è½¬æ¢å¤±è´¥ï¼Œä»ç„¶å°è¯•ä½¿ç”¨åŸå§‹æ ¼å¼ï¼ˆå¯èƒ½APIèƒ½å¤„ç†ï¼‰
      const fileExtension = getFileExtension(originalMimeType);
      return new File([audioBlob], `recording.${fileExtension}`, { type: 'audio/webm' });
    }
  };
  
  // è·å–æ–‡ä»¶æ‰©å±•å
  const getFileExtension = (mimeType: string): string => {
    if (mimeType.includes('wav')) return 'wav';
    if (mimeType.includes('m4a')) return 'm4a';
    if (mimeType.includes('mp4')) return 'mp4';
    if (mimeType.includes('mp3') || mimeType.includes('mpeg')) return 'mp3';
    if (mimeType.includes('flac')) return 'flac';
    if (mimeType.includes('ogg')) return 'ogg';
    if (mimeType.includes('webm')) return 'webm';
    return 'webm'; // é»˜è®¤
  };
  
  // è·å–å¹²å‡€çš„MIMEç±»å‹ï¼ˆå»é™¤codecä¿¡æ¯ï¼‰
  const getCleanMimeType = (mimeType: string): string => {
    if (mimeType.includes('wav')) return 'audio/wav';
    if (mimeType.includes('m4a')) return 'audio/m4a';
    if (mimeType.includes('mp4')) return 'audio/mp4';
    if (mimeType.includes('mp3') || mimeType.includes('mpeg')) return 'audio/mpeg';
    if (mimeType.includes('flac')) return 'audio/flac';
    if (mimeType.includes('ogg')) return 'audio/ogg';
    if (mimeType.includes('webm')) return 'audio/webm';
    return 'audio/webm'; // é»˜è®¤
  };
  
  // è½¬æ¢ä¸ºWAVæ ¼å¼
  const convertToWav = async (audioBlob: Blob): Promise<File> => {
    return new Promise((resolve, reject) => {
      const audio = new Audio();
      const url = URL.createObjectURL(audioBlob);
      
      audio.onloadeddata = async () => {
        try {
          const audioContext = new (window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();
          const arrayBuffer = await audioBlob.arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          
          // è½¬æ¢ä¸ºWAV
          const wavBlob = await audioBufferToWav(audioBuffer);
          const wavFile = new File([wavBlob], 'recording.wav', { type: 'audio/wav' });
          
          audioContext.close();
          URL.revokeObjectURL(url);
          resolve(wavFile);
        } catch (error) {
          URL.revokeObjectURL(url);
          reject(error);
        }
      };
      
      audio.onerror = () => {
        URL.revokeObjectURL(url);
        reject(new Error('æ— æ³•è§£ç éŸ³é¢‘æ•°æ®'));
      };
      
      audio.src = url;
    });
  };
  
  // å°†AudioBufferè½¬æ¢ä¸ºWAV Blob
  const audioBufferToWav = (audioBuffer: AudioBuffer): Promise<Blob> => {
    return new Promise((resolve) => {
      const numberOfChannels = audioBuffer.numberOfChannels;
      const sampleRate = audioBuffer.sampleRate;
      const format = 1; // PCM
      const bitDepth = 16;
      
      const bytesPerSample = bitDepth / 8;
      const blockAlign = numberOfChannels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = audioBuffer.length * blockAlign;
      const bufferSize = 44 + dataSize;
      
      const arrayBuffer = new ArrayBuffer(bufferSize);
      const dataView = new DataView(arrayBuffer);
      
      // WAV æ–‡ä»¶å¤´
      let offset = 0;
      
      // RIFF chunk descriptor
      writeString(dataView, offset, 'RIFF'); offset += 4;
      dataView.setUint32(offset, 36 + dataSize, true); offset += 4;
      writeString(dataView, offset, 'WAVE'); offset += 4;
      
      // FMT sub-chunk
      writeString(dataView, offset, 'fmt '); offset += 4;
      dataView.setUint32(offset, 16, true); offset += 4;
      dataView.setUint16(offset, format, true); offset += 2;
      dataView.setUint16(offset, numberOfChannels, true); offset += 2;
      dataView.setUint32(offset, sampleRate, true); offset += 4;
      dataView.setUint32(offset, byteRate, true); offset += 4;
      dataView.setUint16(offset, blockAlign, true); offset += 2;
      dataView.setUint16(offset, bitDepth, true); offset += 2;
      
      // Data sub-chunk
      writeString(dataView, offset, 'data'); offset += 4;
      dataView.setUint32(offset, dataSize, true); offset += 4;
      
      // Write PCM samples
      for (let i = 0; i < audioBuffer.length; i++) {
        for (let channel = 0; channel < numberOfChannels; channel++) {
          const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(channel)[i]));
          const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
          dataView.setInt16(offset, intSample, true);
          offset += 2;
        }
      }
      
      resolve(new Blob([arrayBuffer], { type: 'audio/wav' }));
    });
  };
  
  // å†™å…¥å­—ç¬¦ä¸²åˆ°DataView
  const writeString = (dataView: DataView, offset: number, string: string): void => {
    for (let i = 0; i < string.length; i++) {
      dataView.setUint8(offset + i, string.charCodeAt(i));
    }
  };

  const handleRecordingComplete = async (audioBlob: Blob) => {
    console.log('ğŸ™ï¸ handleRecordingComplete è¢«è°ƒç”¨ï¼ŒéŸ³é¢‘æ•°æ®å¤§å°:', audioBlob.size, 'bytes');
    
    if (audioBlob.size === 0) {
      console.error('âŒ éŸ³é¢‘æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œè½¬å½•');
      setError('å½•éŸ³æ•°æ®ä¸ºç©ºï¼Œè¯·é‡æ–°å½•åˆ¶');
      return;
    }
    
    try {
      // è½¬æ¢ä¸ºAPIæ”¯æŒçš„æ ¼å¼
      const audioFile = await convertAudioToSupportedFormat(audioBlob);
      console.log('ğŸ“ æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶:', audioFile.name, 'å¤§å°:', audioFile.size, 'bytes', 'æ ¼å¼:', audioFile.type);
      
      console.log('ğŸš€ å‡†å¤‡å¼€å§‹è½¬å½•...');
      handleTranscription(audioFile);
    } catch (error) {
      console.error('âŒ éŸ³é¢‘æ ¼å¼å¤„ç†å¤±è´¥:', error);
      setError('éŸ³é¢‘æ ¼å¼å¤„ç†å¤±è´¥ï¼Œè¯·é‡æ–°å½•åˆ¶');
    }
  };

  // æ£€æŸ¥æµè§ˆå™¨å…¼å®¹æ€§çš„å‡½æ•°
  const checkBrowserCompatibility = () => {
    const errors = [];
    
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      errors.push('âŒ æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒåª’ä½“è®¾å¤‡è®¿é—® (getUserMedia)');
    }
    
    if (!window.MediaRecorder) {
      errors.push('âŒ æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒåª’ä½“å½•åˆ¶ (MediaRecorder)');
    }
    
    if (!window.AudioContext && !(window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext) {
      errors.push('âŒ æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å¤„ç† (AudioContext)');
    }
    
    return errors;
  };

  const handleOpenRecordingModal = () => {
    // åœ¨æ‰“å¼€å½•éŸ³å¼¹çª—å‰æ£€æŸ¥æµè§ˆå™¨å…¼å®¹æ€§
    const compatibilityErrors = checkBrowserCompatibility();
    if (compatibilityErrors.length > 0) {
      const errorMessage = 'ğŸš« å½•éŸ³åŠŸèƒ½ä¸å¯ç”¨:\n\n' + 
                          compatibilityErrors.join('\n') + 
                          '\n\nğŸ’¡ å»ºè®®ä½¿ç”¨ä»¥ä¸‹æµè§ˆå™¨:\n' +
                          'â€¢ Chrome 60+\n' +
                          'â€¢ Firefox 55+\n' +
                          'â€¢ Safari 14+\n' +
                          'â€¢ Edge 79+';
      alert(errorMessage);
      return;
    }
    
    setIsRecordingModalOpen(true);
  };

  const handleCloseRecordingModal = () => {
    setIsRecordingModalOpen(false);
  };


  const handleClearAll = () => {
    // Clear all content including uploaded file and transcription results
    setTranscriptionResult(null);
    setUploadedFile(null);
    setError(null);
    setUsageLimitWarning(null);
    setFileUploadError(null);
    setFileDetectedDuration(null);
    setIsProcessing(false);
    localStorage.removeItem('transcriptionResult');
  };

  const handleExportToWord = () => {
    if (transcriptionResult) {
      exportToWord(transcriptionResult.text, 'transcription');
    }
  };


  return (
    <div className="audio-to-text-page">
      <div className="container">
        <div className="page-header">
          <h1 className="page-title">{t('audioToText.title')}</h1>
          <p className="page-subtitle">
            {user ? (
              (() => {
                const isGuestUser = isGuest || user.userType === 'guest';
                const isAdmin = user?.email === 'max.z.software@gmail.com';
                if (isAdmin) {
                  return 'ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰: ç„¡åˆ¶é™';
                }
                const totalQuota = isGuestUser ? 5 : (user.quotaMinutes || 10);
                const remainingTime = Math.max(0, totalQuota - currentUsedMinutes);
                return `æ®‹ã‚Šæ™‚é–“: ${formatRemainingTime(remainingTime)}`;
              })()
            ) : t('audioToText.subtitle')}
          </p>
        </div>

        <div className="main-content">
          {/* Left side - Input section */}
          <div className="input-section">
            <div className="card">
              <h2>
                {t('audioToText.audioInputMethod')}
              </h2>
              
              {/* Upload Section */}
              <div className="audio-upload-area">
                <h3>
                  {t('audioToText.uploadAudio')}
                </h3>
                <div
                  {...getRootProps()}
                  className={`dropzone ${isDragActive ? 'active' : ''} ${uploadedFile ? 'has-file' : ''}`}
                >
                  <input {...getInputProps()} />
                  {uploadedFile ? (
                    <div className="uploaded-file">
                      <div className="file-icon" style={{ fontSize: '32px', color: 'var(--success-green)' }}>â™ª</div>
                      <div className="file-info">
                        <div className="file-name">{uploadedFile.name}</div>
                        <div className="file-size">
                          {(uploadedFile.size / (1024 * 1024)).toFixed(2)} MB
                        </div>
                        {fileDetectedDuration !== null && (
                          <div className="file-duration" style={{ color: 'var(--primary-blue)', fontSize: 'var(--font-size-footnote)', marginTop: 'var(--spacing-xs)' }}>
                            éŸ³é¢‘æ—¶é•¿: {formatDuration(fileDetectedDuration)}
                          </div>
                        )}
                        <div className="file-status" style={{ color: 'var(--success-green)', fontSize: 'var(--font-size-footnote)', marginTop: 'var(--spacing-xs)' }}>
                          {t('audioToText.fileUploaded')}
                        </div>
                      </div>
                    </div>
                  ) : (
                    <div className="dropzone-content">
                      <div className="upload-icon">ğŸ“</div>
                      <p>{isDragActive ? t('audioToText.dragDropActiveText') : t('audioToText.dragDropText')}</p>
                      <p className="file-info">{t('audioToText.supportedFormats')}</p>
                    </div>
                  )}
                </div>
              </div>

              {/* Divider */}
              <div className="input-divider">
                <div className="divider-line"></div>
                <span className="divider-text">{t('audioToText.dividerOr')}</span>
                <div className="divider-line"></div>
              </div>

              {/* Record Section */}
              <div className="audio-record-area">
                <h3>
                  {t('audioToText.liveRecording')}
                </h3>
                <div className="record-controls">
                  <button 
                    onClick={handleOpenRecordingModal}
                    className="button button-primary start-recording-button"
                  >
                    <span className="mic-icon">ğŸ™ï¸</span>
                    {t('audioToText.liveRecording')}
                  </button>
                </div>
              </div>
            </div>
          </div>

          {/* Right side - Output section */}
          <div className="output-section">
            <div className="output-container">
              {/* Output textarea - always visible */}
              <div className="output-area card">
                <textarea
                  value={transcriptionResult?.text || ''}
                  readOnly
                  className="output-textarea"
                  placeholder={transcriptionResult ? t('audioToText.transcriptionComplete') : t('audioToText.outputPlaceholder')}
                />
              </div>
              
              {/* Control buttons outside the textarea */}
              <div className="output-controls">
                <button
                  onClick={handleStartTranscription}
                  className={`button action-button button-primary ${isProcessing ? 'button-processing' : ''}`}
                  disabled={!uploadedFile || isProcessing}
                >
                  {isProcessing ? t('audioToText.processing') : t('audioToText.startTranscription')}
                </button>
                <button
                  onClick={() => {
                    if (transcriptionResult) {
                      navigator.clipboard.writeText(transcriptionResult.text);
                    }
                  }}
                  className="button action-button button-secondary"
                  disabled={!transcriptionResult || isGuest}
                >
                  {t('common.copy')}
                </button>
                <button
                  onClick={() => {
                    handleExportToWord();
                  }}
                  className="button action-button button-secondary"
                  disabled={!transcriptionResult}
                >
                  {t('common.export')}
                </button>
                <button
                  onClick={handleClearAll}
                  className="button action-button button-warning"
                  disabled={!uploadedFile && !transcriptionResult}
                >
                  {t('common.clear')}
                </button>
              </div>
            </div>
          </div>
        </div>

        {isProcessing && (
          <div className="processing-indicator card">
            <div className="loading-spinner"></div>
            <p>{t('audioToText.processing')}</p>
            {uploadedFile && uploadedFile.size > 25 * 1024 * 1024 && (
              <p style={{ fontSize: 'var(--font-size-footnote)', color: 'var(--text-secondary)', marginTop: 'var(--spacing-sm)' }}>
                å¤§æ–‡ä»¶æ­£åœ¨åˆ†æ®µå¤„ç†ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...
              </p>
            )}
          </div>
        )}

        {fileUploadError && (
          <div className="error-message card" style={{ backgroundColor: 'var(--error-red)', color: 'white' }}>
            <p>âš ï¸ {fileUploadError}</p>
          </div>
        )}

        {usageLimitWarning && (
          <div className="warning-message card" style={{ backgroundColor: 'var(--warning-orange)', color: 'white' }}>
            <p>{usageLimitWarning}</p>
          </div>
        )}

        {error && (
          <div className="error-message card" style={{ backgroundColor: 'var(--error-red)', color: 'white' }}>
            <p>{error}</p>
          </div>
        )}

        {/* Recording Modal */}
        <RecordingModal
          isOpen={isRecordingModalOpen}
          onClose={handleCloseRecordingModal}
          onRecordingComplete={handleRecordingComplete}
        />
      </div>
    </div>
  );
};

export default AudioToText;