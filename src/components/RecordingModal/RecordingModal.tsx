import React, { useState, useRef, useEffect } from 'react';
import { useTranslation } from 'react-i18next';
import { useAuth } from '../../hooks/useAuth';
import { usageTracker } from '../../services/usageTracker';
import { formatRemainingTime, formatRecordingTime } from '../../utils/timeFormat';
import './RecordingModal.css';

interface RecordingModalProps {
  isOpen: boolean;
  onClose: () => void;
  onRecordingComplete: (audioBlob: Blob) => void;
}

const RecordingModal: React.FC<RecordingModalProps> = ({ isOpen, onClose, onRecordingComplete }) => {
  const { t } = useTranslation();
  const { user, isGuest, ensureGuestMode } = useAuth();
  
  // å®‰å…¨çš„ç¿»è¯‘å‡½æ•°ï¼Œå¸¦æœ‰é»˜è®¤å€¼
  const safeT = (key: string, defaultValue: string, options?: Record<string, unknown>): string => {
    try {
      const result = t(key, options);
      return typeof result === 'string' && result !== key ? result : defaultValue;
    } catch (error) {
      console.error(`Translation error for key: ${key}`, error);
      return defaultValue;
    }
  };
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioData, setAudioData] = useState<number[]>(Array(32).fill(0));
  const [hasRecording, setHasRecording] = useState(false);
  const [limitReached, setLimitReached] = useState(false);
  const [currentUsedMinutes, setCurrentUsedMinutes] = useState(0);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const visualizationIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordedAudioBlobRef = useRef<Blob | null>(null);

  // æ›´æ–°ä½¿ç”¨é‡æ•°æ®
  const updateUsageData = async () => {
    try {
      const realUsedMinutes = await usageTracker.getCurrentUserTotalUsage();
      setCurrentUsedMinutes(realUsedMinutes);
      console.log('ğŸ”„ å½•éŸ³å¼¹çª—ä½¿ç”¨é‡æ•°æ®å·²æ›´æ–°:', realUsedMinutes.toFixed(2), 'åˆ†é’Ÿ');
    } catch (error) {
      console.error('âŒ æ›´æ–°ä½¿ç”¨é‡æ•°æ®å¤±è´¥:', error);
      // å›é€€åˆ°localStorageæ•°æ®
      const fallbackUsage = Number(localStorage.getItem('guestUsedMinutes') || '0');
      setCurrentUsedMinutes(fallbackUsage);
    }
  };

  useEffect(() => {
    return () => {
      cleanup();
    };
  }, []);

  // ç¡®ä¿åœ¨æ¨¡æ€æ¡†æ‰“å¼€æ—¶è®¿å®¢æ¨¡å¼çŠ¶æ€æ­£ç¡®ï¼Œå¹¶æ›´æ–°ä½¿ç”¨é‡æ•°æ®
  useEffect(() => {
    if (isOpen) {
      // æ›´æ–°ä½¿ç”¨é‡æ•°æ®
      updateUsageData();
      
      // ç¡®ä¿è®¿å®¢æ¨¡å¼çŠ¶æ€æ­£ç¡®
      if (!user && localStorage.getItem('guestMode') === 'true') {
        console.log('ğŸ™ï¸ å½•éŸ³æ¨¡æ€æ¡†æ‰“å¼€ï¼Œå·²æœ‰è®¿å®¢æ¨¡å¼æ ‡è¯†ï¼Œæ›´æ–°è®¿å®¢çŠ¶æ€...');
        ensureGuestMode().catch(error => {
          console.error('âŒ è®¿å®¢æ¨¡å¼æ›´æ–°å¤±è´¥:', error);
        });
      }
    }
  }, [isOpen, user, ensureGuestMode]);

  const cleanup = () => {
    console.log('ğŸ§¹ æ¸…ç†å½•éŸ³èµ„æº...');
    
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
      intervalRef.current = null;
    }
    if (visualizationIntervalRef.current) {
      clearInterval(visualizationIntervalRef.current);
      visualizationIntervalRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('ğŸ›‘ åœæ­¢éŸ³é¢‘è½¨é“:', track.kind);
      });
      streamRef.current = null;
    }
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close().catch(err => {
        console.warn('âš ï¸ éŸ³é¢‘ä¸Šä¸‹æ–‡å…³é—­å¤±è´¥:', err);
      });
      audioContextRef.current = null;
    }
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current = null;
    }
    if (analyserRef.current) {
      analyserRef.current = null;
    }
    
    console.log('âœ… å½•éŸ³èµ„æºæ¸…ç†å®Œæˆ');
  };

  // ç»Ÿä¸€çš„é…é¢æ£€æŸ¥å‡½æ•°
  const getUserQuotaInfo = () => {
    let totalMinutes = 0;
    let usedMinutes = 0;
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºæ¸¸å®¢ç”¨æˆ·ï¼ˆåŒ…æ‹¬æœªç™»å½•ç”¨æˆ·ï¼‰
    const isGuestUser = isGuest || !user || user.userType === 'guest';
    
    if (isGuestUser) {
      totalMinutes = 5; // æ‰€æœ‰æ¸¸å®¢ç”¨æˆ·5åˆ†é’Ÿ
      // ä½¿ç”¨çœŸå®ä½¿ç”¨é‡æ•°æ®
      usedMinutes = currentUsedMinutes;
    } else if (user) {
      // è®¤è¯ç”¨æˆ·ï¼ˆè¯•ç”¨æˆ–ä»˜è´¹ç”¨æˆ·ï¼‰
      totalMinutes = user.quotaMinutes || 10;
      // ä½¿ç”¨çœŸå®ä½¿ç”¨é‡æ•°æ®
      usedMinutes = currentUsedMinutes;
    }
    
    const remainingMinutes = Math.max(0, totalMinutes - usedMinutes);
    
    return { totalMinutes, usedMinutes, remainingMinutes };
  };

  // è·å–ç”¨æˆ·ç±»å‹æ˜¾ç¤ºæ–‡æœ¬
  const getUserTypeText = () => {
    // ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºè®¿å®¢ç™»å½•æ¨¡å¼
    if (isGuest && localStorage.getItem('guestMode') === 'true') {
      return safeT('audioToText.guestUser', 'è®¿å®¢ç”¨æˆ·');
    }
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºè®¤è¯ç”¨æˆ·
    if (user && localStorage.getItem('authToken')) {
      if (user.email === 'max.z.software@gmail.com') {
        return safeT('audioToText.adminUser', 'ç®¡ç†å‘˜');
      } else if (user.userType === 'paid') {
        return safeT('audioToText.paidUser', 'ä»˜è´¹ç”¨æˆ·');
      } else if (user.userType === 'trial') {
        return safeT('audioToText.trialUser', 'è¯•ç”¨ç”¨æˆ·');
      }
    }
    
    // å®Œå…¨æœªç™»å½•çš„æƒ…å†µ - æ˜¾ç¤º"æœªç™»å½•"è€Œä¸æ˜¯"è®¿å®¢ç”¨æˆ·"
    if (!localStorage.getItem('authToken') && !isGuest) {
      return safeT('audioToText.unauthenticated', 'æœªç™»å½•');
    }
    
    // å…œåº•æƒ…å†µ
    return safeT('audioToText.guestUser', 'è®¿å®¢ç”¨æˆ·');
  };

  const startRecording = async () => {
    try {
      // æ£€æŸ¥ç”¨æˆ·å‰©ä½™é…é¢
      const { remainingMinutes } = getUserQuotaInfo();
      if (remainingMinutes <= 0) {
        const message = `â° ${safeT('audioToText.recordingQuotaExhausted', 'æ‚¨çš„é…é¢å·²ç”¨å®Œï¼Œæ— æ³•å¼€å§‹å½•éŸ³')}`;
        alert(message);
        return;
      }

      // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒåª’ä½“å½•åˆ¶
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeã€Firefoxæˆ–Safariæµè§ˆå™¨');
      }

      if (!window.MediaRecorder) {
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒMediaRecorder APIï¼Œè¯·æ›´æ–°æ‚¨çš„æµè§ˆå™¨');
      }

      console.log('ğŸ¤ å¼€å§‹è¯·æ±‚éº¦å…‹é£æƒé™...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        } 
      });
      console.log('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸ');
      streamRef.current = stream;

      // Set up audio analysis for waveform visualization
      audioContextRef.current = new (window.AudioContext || (window as typeof window & { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      analyserRef.current = audioContextRef.current.createAnalyser();
      
      analyserRef.current.fftSize = 256;
      analyserRef.current.smoothingTimeConstant = 0.1;
      analyserRef.current.minDecibels = -90;
      analyserRef.current.maxDecibels = -10;
      
      source.connect(analyserRef.current);

      // æ£€æŸ¥MediaRecorderæ”¯æŒçš„æ ¼å¼ï¼Œä¼˜å…ˆé€‰æ‹©OpenAI APIå…¼å®¹çš„æ ¼å¼
      const mimeTypes = [
        // OpenAI APIç›´æ¥æ”¯æŒçš„æ ¼å¼ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        'audio/wav',
        'audio/mp4',
        'audio/mpeg',
        'audio/webm', // è™½ç„¶æ”¯æŒï¼Œä½†å¯èƒ½éœ€è¦è½¬æ¢
        'audio/ogg;codecs=opus', // æ”¯æŒï¼Œä½†éœ€è¦æ­£ç¡®çš„æ‰©å±•å
        'audio/ogg',
        'audio/webm;codecs=opus',
        // å…¶ä»–æ ¼å¼ä½œä¸ºå¤‡é€‰
        'audio/mp3'
      ];
      
      let selectedMimeType = '';
      for (const mimeType of mimeTypes) {
        if (MediaRecorder.isTypeSupported(mimeType)) {
          selectedMimeType = mimeType;
          console.log('âœ… æ‰¾åˆ°æ”¯æŒçš„æ ¼å¼:', mimeType);
          break;
        }
      }
      
      if (!selectedMimeType) {
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒä»»ä½•éŸ³é¢‘å½•åˆ¶æ ¼å¼');
      }
      
      console.log('ğŸµ é€‰æ‹©çš„éŸ³é¢‘æ ¼å¼:', selectedMimeType);
      
      // Set up MediaRecorder
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: selectedMimeType,
        audioBitsPerSecond: 128000
      });
      audioChunksRef.current = [];
      
      console.log('ğŸ“± MediaRecorder åˆå§‹åŒ–å®Œæˆ');

      mediaRecorderRef.current.ondataavailable = (event) => {
        console.log('ğŸ“Š æ”¶åˆ°å½•éŸ³æ•°æ®:', event.data.size, 'bytes');
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorderRef.current.onerror = (event) => {
        console.error('ğŸš« MediaRecorder é”™è¯¯:', event);
        alert('å½•åˆ¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•');
      };
      
      mediaRecorderRef.current.onstart = () => {
        console.log('ğŸ¬ å½•åˆ¶å¼€å§‹');
      };
      
      mediaRecorderRef.current.onpause = () => {
        console.log('â¸ï¸ å½•åˆ¶æš‚åœ');
      };
      
      mediaRecorderRef.current.onresume = () => {
        console.log('â–¶ï¸ å½•åˆ¶æ¢å¤');
      };

      mediaRecorderRef.current.onstop = () => {
        console.log('ğŸ¬ MediaRecorder onstop äº‹ä»¶è§¦å‘');
        console.log('ğŸ“Š AudioChunks æ•°é‡:', audioChunksRef.current.length);
        
        if (audioChunksRef.current.length === 0) {
          console.error('âš ï¸ æ²¡æœ‰å½•éŸ³æ•°æ®chunks');
          return;
        }
        
        // ä½¿ç”¨å½•åˆ¶æ—¶çš„å®é™…MIMEç±»å‹
        const mimeType = mediaRecorderRef.current?.mimeType || 'audio/webm';
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
        recordedAudioBlobRef.current = audioBlob;
        setHasRecording(true);
        
        console.log('ğŸ“¦ å½•éŸ³å®Œæˆï¼Œæ•°æ®å¤§å°:', audioBlob.size, 'bytes');
        console.log('âœ… hasRecording çŠ¶æ€å·²è®¾ç½®ä¸º true');
      };

      // å¼€å§‹å½•åˆ¶ï¼Œæ¯ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
      mediaRecorderRef.current.start(1000);
      setIsRecording(true);
      console.log('ğŸ™ï¸ å½•åˆ¶å·²å¯åŠ¨');
      setIsPaused(false);
      setRecordingTime(0);

      // Start timer with usage limit checking
      intervalRef.current = setInterval(() => {
        setRecordingTime((prev) => {
          const newTime = prev + 1;
          const newTimeMinutes = newTime / 60;
          
          // è·å–ç”¨æˆ·é…é¢ä¿¡æ¯
          const { remainingMinutes } = getUserQuotaInfo();
          
          // æ£€æŸ¥å½•åˆ¶æ—¶é•¿æ˜¯å¦è¶…è¿‡å‰©ä½™é…é¢
          if (newTimeMinutes >= remainingMinutes) {
            setLimitReached(true);
            setTimeout(stopRecording, 100);
            return newTime;
          }
          
          // é¢å¤–æ£€æŸ¥ï¼šé˜²æ­¢å•æ¬¡å½•éŸ³è¶…è¿‡10åˆ†é’Ÿï¼ˆæŠ€æœ¯é™åˆ¶ï¼‰
          const MAX_SINGLE_RECORDING_MINUTES = 10;
          if (newTimeMinutes >= MAX_SINGLE_RECORDING_MINUTES) {
            setLimitReached(true);
            setTimeout(stopRecording, 100);
            return newTime;
          }
          
          return newTime;
        });
      }, 1000);

      // Start audio visualization
      startAudioVisualization();
    } catch (error) {
      console.error('ğŸš« å½•éŸ³å¯åŠ¨å¤±è´¥:', error);
      
      let errorMessage = '';
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError' || error.message.includes('Permission denied')) {
          errorMessage = 'ğŸš« éº¦å…‹é£æƒé™è¢«æ‹’ç»ã€‚è¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®æƒé™ï¼Œç„¶ååˆ·æ–°é¡µé¢é‡è¯•ã€‚';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'ğŸ¤ æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·æ£€æŸ¥æ‚¨çš„éº¦å…‹é£æ˜¯å¦å·²è¿æ¥ã€‚';
        } else if (error.name === 'NotSupportedError') {
          errorMessage = 'ğŸŒ æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ã€‚è¯·ä½¿ç”¨Chromeã€Firefoxæˆ–Safariæµè§ˆå™¨ã€‚';
        } else if (error.message.includes('MediaRecorder')) {
          errorMessage = 'ğŸ“± æ‚¨çš„æµè§ˆå™¨ç‰ˆæœ¬è¿‡æ—§ï¼Œä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ã€‚è¯·æ›´æ–°æ‚¨çš„æµè§ˆå™¨ã€‚';
        } else {
          errorMessage = `âŒ å½•éŸ³å¯åŠ¨å¤±è´¥: ${error.message}`;
        }
      } else {
        errorMessage = 'âŒ æœªçŸ¥é”™è¯¯ï¼Œå½•éŸ³åŠŸèƒ½æ— æ³•å¯åŠ¨ã€‚';
      }
      
      alert(errorMessage);
    }
  };

  const pauseRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.pause();
      setIsPaused(true);
      
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      if (visualizationIntervalRef.current) {
        clearInterval(visualizationIntervalRef.current);
      }
      setAudioData(Array(32).fill(0));
    }
  };

  const resumeRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'paused') {
      mediaRecorderRef.current.resume();
      setIsPaused(false);
      
      // Restart timer with usage limit checking
      intervalRef.current = setInterval(() => {
        setRecordingTime((prev) => {
          const newTime = prev + 1;
          const newTimeMinutes = newTime / 60;
          
          // è·å–ç”¨æˆ·é…é¢ä¿¡æ¯
          const { remainingMinutes } = getUserQuotaInfo();
          
          // æ£€æŸ¥å½•åˆ¶æ—¶é•¿æ˜¯å¦è¶…è¿‡å‰©ä½™é…é¢
          if (newTimeMinutes >= remainingMinutes) {
            setLimitReached(true);
            setTimeout(stopRecording, 100);
            return newTime;
          }
          
          // é¢å¤–æ£€æŸ¥ï¼šé˜²æ­¢å•æ¬¡å½•éŸ³è¶…è¿‡10åˆ†é’Ÿï¼ˆæŠ€æœ¯é™åˆ¶ï¼‰
          const MAX_SINGLE_RECORDING_MINUTES = 10;
          if (newTimeMinutes >= MAX_SINGLE_RECORDING_MINUTES) {
            setLimitReached(true);
            setTimeout(stopRecording, 100);
            return newTime;
          }
          
          return newTime;
        });
      }, 1000);
      
      // Restart visualization
      startAudioVisualization();
    }
  };

  const stopRecording = () => {
    console.log('ğŸ›‘ åœæ­¢å½•éŸ³');
    console.log('ğŸ“Š å½“å‰ MediaRecorder çŠ¶æ€:', mediaRecorderRef.current?.state);
    
    if (mediaRecorderRef.current && 
        (mediaRecorderRef.current.state === 'recording' || mediaRecorderRef.current.state === 'paused')) {
      console.log('â¹ï¸ è°ƒç”¨ MediaRecorder.stop()');
      mediaRecorderRef.current.stop();
    }

    if (intervalRef.current) {
      clearInterval(intervalRef.current);
    }
    if (visualizationIntervalRef.current) {
      clearInterval(visualizationIntervalRef.current);
    }

    setIsRecording(false);
    setIsPaused(false);
    setAudioData(Array(32).fill(0));
    
    console.log('âœ… å½•éŸ³çŠ¶æ€å·²æ¸…ç†');
  };

  const startAudioVisualization = () => {
    visualizationIntervalRef.current = setInterval(() => {
      if (!analyserRef.current || (!isRecording || isPaused)) {
        return;
      }

      try {
        const bufferLength = analyserRef.current.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        analyserRef.current.getByteFrequencyData(dataArray);

        // Calculate average volume
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
          sum += dataArray[i];
        }
        const averageVolume = sum / bufferLength;
        const normalizedVolume = Math.min(1, averageVolume / 128);

        // Generate bars
        const bars = [];
        const barCount = 32;
        
        for (let i = 0; i < barCount; i++) {
          const freqIndex = Math.floor((i / barCount) * bufferLength);
          let barHeight = dataArray[freqIndex] / 255;
          
          barHeight = Math.max(barHeight, normalizedVolume * 0.3);
          barHeight = Math.min(1, barHeight * 2);
          
          const randomVariation = (Math.random() - 0.5) * 0.1 * barHeight;
          barHeight = Math.max(0.05, Math.min(1, barHeight + randomVariation));
          
          bars.push(barHeight);
        }
        
        setAudioData(bars);
      } catch (error) {
        console.error('Error in visualization:', error);
      }
    }, 100);
  };

  const handleStartTranscription = () => {
    console.log('ğŸš€ å¼€å§‹è½¬æ–‡å­—å¤„ç†...');
    console.log('ğŸ“Š hasRecording:', hasRecording);
    console.log('ğŸ“Š recordedAudioBlobRef æ˜¯å¦æœ‰æ•°æ®:', !!recordedAudioBlobRef.current);
    console.log('ğŸ“Š audioChunks æ•°é‡:', audioChunksRef.current.length);
    
    // ä¼˜å…ˆä½¿ç”¨å·²ä¿å­˜çš„å½•éŸ³ Blob
    if (hasRecording && recordedAudioBlobRef.current) {
      console.log('âœ… ä½¿ç”¨å·²ä¿å­˜çš„å½•éŸ³æ•°æ®ï¼Œå¤§å°:', recordedAudioBlobRef.current.size, 'bytes');
      onRecordingComplete(recordedAudioBlobRef.current);
      handleClose();
      return;
    }
    
    // å¤‡ç”¨æ–¹æ¡ˆï¼šä» chunks é‡æ–°åˆ›å»º
    if (hasRecording && audioChunksRef.current.length > 0) {
      console.log('ğŸ”„ ä»chunksé‡æ–°åˆ›å»ºéŸ³é¢‘æ•°æ®');
      // ä½¿ç”¨å½•åˆ¶æ—¶çš„å®é™…MIMEç±»å‹
      const mimeType = mediaRecorderRef.current?.mimeType || 'audio/webm';
      const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
      console.log('ğŸ“¦ é‡æ–°åˆ›å»ºçš„éŸ³é¢‘æ•°æ®ï¼Œå¤§å°:', audioBlob.size, 'bytes, ç±»å‹:', mimeType);
      onRecordingComplete(audioBlob);
      handleClose();
      return;
    }
    
    // æ²¡æœ‰å½•éŸ³æ•°æ®
    console.error('âŒ æ²¡æœ‰æ‰¾åˆ°å½•éŸ³æ•°æ®');
    alert(safeT('audioToText.noRecordingData', 'æ²¡æœ‰å½•éŸ³æ•°æ®ï¼Œè¯·å…ˆå½•åˆ¶éŸ³é¢‘'));
  };

  const handleClose = () => {
    cleanup();
    setIsRecording(false);
    setIsPaused(false);
    setRecordingTime(0);
    setAudioData(Array(32).fill(0));
    setHasRecording(false);
    setLimitReached(false);
    audioChunksRef.current = [];
    recordedAudioBlobRef.current = null;
    onClose();
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  if (!isOpen) return null;

  return (
    <div className="modal-overlay" onClick={handleClose}>
      <div className="recording-modal" onClick={(e) => e.stopPropagation()}>
        <div className="modal-header">
          <h2>{safeT('audioToText.liveRecording', 'å®æ—¶å½•åˆ¶')}</h2>
          <button className="modal-close" onClick={handleClose}>Ã—</button>
        </div>
        
        <div className="modal-content">
          {/* Waveform visualization */}
          <div className="waveform-container">
            <div className="waveform">
              {audioData.map((height, i) => (
                <div
                  key={i}
                  className="waveform-bar"
                  style={{
                    height: `${Math.max(8, height * 60)}px`,
                    backgroundColor: isRecording && !isPaused ? 'var(--primary-blue)' : 'var(--light-gray)',
                    opacity: Math.max(0.3, 0.5 + height * 0.5),
                    transition: 'height 0.1s ease-out, opacity 0.1s ease-out'
                  }}
                />
              ))}
            </div>
          </div>

          {/* Recording time and limit info */}
          <div className="recording-time">
            {formatRecordingTime(recordingTime)}
          </div>
          
          {/* Universal quota display */}
          <div className="usage-limit-info">
            <p className="limit-text">
              ç·åˆ©ç”¨å¯èƒ½æ®‹ã‚Š: {formatRemainingTime(getUserQuotaInfo().remainingMinutes)} | ç¾åœ¨ã®éŒ²éŸ³: {formatRecordingTime(recordingTime)}
            </p>
            <p className="user-type-info" style={{ fontSize: '12px', color: 'var(--text-secondary)', marginTop: '4px' }}>
              ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—: {getUserTypeText()} | 
              ç·åˆ©ç”¨æ : {formatRemainingTime(getUserQuotaInfo().totalMinutes)}
            </p>
          </div>
          
          {limitReached && (
            <div className="limit-reached-warning" style={{ 
              backgroundColor: '#ff6b35', 
              color: 'white', 
              padding: '10px', 
              borderRadius: '5px',
              marginTop: '10px'
            }}>
              {/* æ ¹æ®ç”¨æˆ·çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„æç¤º */}
              {!isGuest && !localStorage.getItem('authToken') ? (
                // æœªç™»å½•ç”¨æˆ·çš„æç¤º
                <div>
                  <p>{safeT('audioToText.guestQuotaReachedTitle', 'â° å·²è¾¾åˆ°ä½¿ç”¨ä¸Šé™ï¼Œå½•éŸ³å·²è‡ªåŠ¨åœæ­¢ã€‚')}</p>
                  <p style={{ fontSize: '14px', marginTop: '5px' }}>
                    {safeT('audioToText.guestTrialComplete', 'ğŸ‰ è®¿å®¢ä½“éªŒå·²ç»“æŸï¼æ³¨å†Œè´¦æˆ·å¯è·å¾—10åˆ†é’Ÿè¯•ç”¨æ—¶é•¿ã€‚')}
                  </p>
                </div>
              ) : (
                // å·²ç™»å½•ç”¨æˆ·çš„åŸæœ‰æç¤º
                <div>
                  <p>â° éŒ²éŸ³ãŒè‡ªå‹•åœæ­¢ã•ã‚Œã¾ã—ãŸ</p>
                  <p style={{ fontSize: '14px', marginTop: '5px' }}>
                    {getUserQuotaInfo().remainingMinutes <= 0 
                      ? `ğŸ“¢ åˆ©ç”¨æ ã‚’ä½¿ã„åˆ‡ã‚Šã¾ã—ãŸã€‚éŒ²éŸ³æ™‚é–“: ${formatRecordingTime(recordingTime)}`
                      : `ğŸ“¢ å˜å›éŒ²éŸ³ãŒ10åˆ†ã®æŠ€è¡“ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚éŒ²éŸ³æ™‚é–“: ${formatRecordingTime(recordingTime)}`
                    }
                  </p>
                  <p style={{ fontSize: '14px', marginTop: '5px' }}>
                    ğŸ’¡ ã“ã®éŒ²éŸ³ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹ã‹ã€æ–°ã—ãéŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã™ã€‚æ–‡å­—èµ·ã“ã—æ™‚ã¯æ®‹ã‚Šåˆ©ç”¨æ ã«å¿œã˜ã¦å‡¦ç†ã•ã‚Œã¾ã™ã€‚
                  </p>
                </div>
              )}
            </div>
          )}

          {/* Control buttons */}
          <div className="modal-controls">
            {!isRecording && !hasRecording && (
              <button onClick={startRecording} className="button button-primary">
                <span className="mic-icon">â—‰</span>
                {safeT('common.start', 'å¼€å§‹')}
              </button>
            )}
            
            {isRecording && !isPaused && (
              <>
                <button onClick={pauseRecording} className="button button-secondary">
                  {safeT('common.stop', 'åœæ­¢')}
                </button>
                <button onClick={stopRecording} className="button button-warning">
                  {safeT('audioToText.completeRecording', 'å®Œæˆå½•åˆ¶')}
                </button>
              </>
            )}
            
            {isRecording && isPaused && (
              <>
                <button onClick={resumeRecording} className="button button-primary">
                  {safeT('audioToText.continueRecording', 'ç»§ç»­å½•åˆ¶')}
                </button>
                <button onClick={stopRecording} className="button button-warning">
                  {safeT('audioToText.completeRecording', 'å®Œæˆå½•åˆ¶')}
                </button>
              </>
            )}
            
            {!isRecording && hasRecording && (
              <>
                <button onClick={startRecording} className="button button-secondary">
                  {safeT('audioToText.reRecord', 'é‡æ–°å½•åˆ¶')}
                </button>
                <button 
                  onClick={handleStartTranscription} 
                  className="button button-primary button-highlighted"
                >
                  {safeT('audioToText.startTranscription', 'å¼€å§‹è½¬å†™')}
                </button>
              </>
            )}
          </div>
        </div>
      </div>
    </div>
  );
};

export default RecordingModal;